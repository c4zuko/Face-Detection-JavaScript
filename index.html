<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100vw;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        canvas {
            position: absolute;
        }
    </style>
</head>

<body>
    <video id="video" width="640" height="480" autoplay></video>

    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
    <script type="text/javascript">
        async function loadModels() {
            var modelsPath = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.15/model/';
            await faceapi.nets.tinyFaceDetector.loadFromUri(modelsPath);
            await faceapi.nets.faceLandmark68Net.loadFromUri(modelsPath);
            await faceapi.nets.faceRecognitionNet.loadFromUri(modelsPath);
            await faceapi.nets.faceExpressionNet.loadFromUri(modelsPath);
        }

        const video = document.getElementById('video');

        navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
            video.srcObject = stream;
        }).catch(err => {
            console.error("Error accessing media devices.", err);
        });

        video.addEventListener('loadedmetadata', async () => {
            await loadModels();
            const canvas = faceapi.createCanvasFromMedia(video);
            document.body.append(canvas);
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                const detection = await faceapi.detectAllFaces(video,
                    new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();

                const resizedDetections = faceapi.resizeResults(detection, displaySize);
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                faceapi.draw.drawDetections(canvas, resizedDetections);
                faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
                faceapi.draw.drawFaceExpressions(canvas, resizedDetections);
                if (resizedDetections.length > 0) {
                    console.log(resizedDetections[0].expressions.asSortedArray()[0].expression);
                }
            }, 100)
        });

    </script>
</body>

</html>